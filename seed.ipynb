{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3a8b98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.io import decode_image\n",
    "from pathlib import Path\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "611069d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANT_CLASSES = [\n",
    "    'Black-grass',\n",
    "    'Charlock', \n",
    "    'Cleavers',\n",
    "    'Common Chickweed',\n",
    "    'Common wheat',\n",
    "    'Fat Hen',\n",
    "    'Loose Silky-bent',\n",
    "    'Maize',\n",
    "    'Scentless Mayweed',\n",
    "    'Shepherds Purse',\n",
    "    'Small-flowered Cranesbill',\n",
    "    'Sugar beet'\n",
    "]\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "\n",
    "    def __init__(self, rootDir, transform=None):\n",
    "        self.rootDir = Path(rootDir)\n",
    "        self.transforms = transform\n",
    "        self.classes = PLANT_CLASSES\n",
    "        self.classsToidx = {plant : idx for idx, plant in enumerate(PLANT_CLASSES)} #將classString轉成 index 的 dict\n",
    "\n",
    "        self.samples = []\n",
    "        self._load_samples()\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        \"\"\"載入指定path中的資料 將'路徑'和label紀錄到samples中\"\"\"\n",
    "        for class_name in self.classes:\n",
    "            class_dir = self.rootDir / class_name\n",
    "            if class_dir.exists():\n",
    "                for img_path in class_dir.glob('*.png'):\n",
    "                    self.samples.append((str(img_path), self.classsToidx[class_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        try:\n",
    "            image = decode_image(img_path, mode='RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"無法載入圖片{img_path}:{e}\")\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c1a3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.RandomResizedCrop(224), #resnet50標準輸入size\n",
    "    v2.RandomHorizontalFlip(0.5),\n",
    "    v2.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "\n",
    "    v2.RandomRotation(15),\n",
    "    v2.RandomGrayscale(p=0.1),\n",
    "\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "\n",
    "    v2.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],#0~1 float計算的mean\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )#ImageNet 資料的mean 跟 std\n",
    "])\n",
    "\n",
    "transform_val = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],#0~1 float計算的mean\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )#ImageNet 資料的mean 跟 std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0918351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders_with_split(data_dir, batch_size=64, num_workers=2, val_split=0.2):\n",
    "\n",
    "    train_dir = data_dir / 'train'\n",
    "\n",
    "    full_dataset = PlantDataset(\n",
    "        rootDir=train_dir,\n",
    "        transform=None\n",
    "    )\n",
    "\n",
    "    total_size = len(full_dataset)\n",
    "    val_size = int(total_size * val_split)\n",
    "    train_size = total_size - val_size\n",
    "\n",
    "    train_indices, val_indices = random_split(\n",
    "        #為了套不同的transfroms 用idx分割\n",
    "        range(total_size), \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(full_dataset, val_indices)\n",
    "    \n",
    "    train_dataset.dataset.transforms = transform_train\n",
    "    val_dataset.dataset.transforms = transform_val\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "310118eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, rootDir, transform=None):\n",
    "        self.rootDir = Path(rootDir)\n",
    "        self.transforms = transform\n",
    "        self.samples = []\n",
    "        self._load_samples()\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        \"\"\"載入測試資料夾中的所有圖片\"\"\"\n",
    "        for img_path in self.rootDir.glob('*.png'):\n",
    "            self.samples.append(str(img_path))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.samples[index]\n",
    "        try:\n",
    "            image = decode_image(img_path, mode='RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 無法載入圖片 {img_path}: {e}\") \n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        filename = Path(img_path).name\n",
    "        return image, filename\n",
    "\n",
    "def create_test_dataloader(data_dir, batch_size=64, num_workers=2):\n",
    "    \"\"\"建立測試資料載入器\"\"\"\n",
    "    \n",
    "    test_dir = data_dir / 'test'\n",
    "    \n",
    "    test_dataset = TestDataset(\n",
    "        rootDir=test_dir,\n",
    "        transform=transform_val\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    \n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6764abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('./data')\n",
    "train_loader, val_loader = create_dataloaders_with_split(data_dir, batch_size=32, num_workers=0)\n",
    "test_loader = create_test_dataloader(data_dir, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a14e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2084adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 總參數量: 23,532,620\n",
      "🎯 可訓練參數: 23,532,620\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def create_resnet50_model(num_classes=12):\n",
    "    \"\"\"建立 ResNet-50 模型\"\"\"\n",
    "    \n",
    "    # 🎯 載入預訓練模型\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_resnet50_model_freeze(num_classes=12):\n",
    "    \"\"\"建立 ResNet-50 模型\"\"\"\n",
    "    \n",
    "    # 🎯 載入預訓練模型\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_resnet50_model(num_classes=len(PLANT_CLASSES))\n",
    "model = model.to(device)\n",
    "modelFreeze = create_resnet50_model_freeze(num_classes=len(PLANT_CLASSES))\n",
    "modelFreeze = modelFreeze.to(device)\n",
    "\n",
    "# 📊 顯示模型資訊\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"📈 總參數量: {total_params:,}\")\n",
    "print(f\"🎯 可訓練參數: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1c00abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=0.0001  # L2 正則化\n",
    ")\n",
    "    \n",
    "scheduler = StepLR(\n",
    "    optimizer,\n",
    "    step_size=7,    # 每 7 個 epoch 降低學習率\n",
    "    gamma=0.1       # 學習率乘以 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be7a9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"訓練一個 epoch\"\"\"\n",
    "    \n",
    "    model.train()  # 設定為訓練模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(f\"🚂 Epoch {epoch} 訓練中...\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # 📦 資料移到 GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 🔄 前向傳播\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 🔙 反向傳播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 📊 統計\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # 📈 顯示進度\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"  批次 {batch_idx}/{len(train_loader)}: \"\n",
    "                  f\"Loss={loss.item():.4f}, \"\n",
    "                  f\"Acc={100.*correct/total:.2f}%\")\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device, epoch):\n",
    "    \"\"\"驗證一個 epoch\"\"\"\n",
    "    \n",
    "    model.eval()  # 設定為評估模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(f\"✅ Epoch {epoch} 驗證中...\")\n",
    "    \n",
    "    with torch.no_grad():  # 不計算梯度\n",
    "        for images, labels in val_loader:\n",
    "            # 📦 資料移到 GPU\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # 🔄 前向傳播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # 📊 統計\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "072d7a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 開始訓練 ResNet-50\n",
      "==================================================\n",
      "📊 訓練集批次數: 118\n",
      "📊 驗證集批次數: 30\n",
      "⏰ 總訓練輪數: 20\n",
      "==================================================\n",
      "\n",
      "🔄 Epoch 1/20\n",
      "------------------------------\n",
      "🚂 Epoch 1 訓練中...\n",
      "  批次 0/118: Loss=2.4780, Acc=6.25%\n",
      "  批次 10/118: Loss=1.6328, Acc=38.35%\n",
      "  批次 20/118: Loss=1.1615, Acc=51.49%\n",
      "  批次 30/118: Loss=0.4183, Acc=58.06%\n",
      "  批次 40/118: Loss=0.3005, Acc=62.88%\n",
      "  批次 50/118: Loss=0.6914, Acc=65.75%\n",
      "  批次 60/118: Loss=0.6175, Acc=68.14%\n",
      "  批次 70/118: Loss=0.5082, Acc=70.29%\n",
      "  批次 80/118: Loss=0.4150, Acc=72.03%\n",
      "  批次 90/118: Loss=0.6999, Acc=73.18%\n",
      "  批次 100/118: Loss=0.7601, Acc=74.01%\n",
      "  批次 110/118: Loss=0.5192, Acc=74.77%\n",
      "✅ Epoch 1 驗證中...\n",
      "\n",
      "📊 Epoch 1 結果:\n",
      "  🚂 訓練 - Loss: 0.7641, Acc: 75.05%\n",
      "  ✅ 驗證 - Loss: 0.5962, Acc: 82.32%\n",
      "  📅 學習率: 0.001000\n",
      "  🎯 新的最佳模型！驗證準確率: 82.32%\n",
      "\n",
      "🔄 Epoch 2/20\n",
      "------------------------------\n",
      "🚂 Epoch 2 訓練中...\n",
      "  批次 0/118: Loss=0.2128, Acc=96.88%\n",
      "  批次 10/118: Loss=0.3491, Acc=86.93%\n",
      "  批次 20/118: Loss=0.1346, Acc=88.24%\n",
      "  批次 30/118: Loss=0.1556, Acc=87.40%\n",
      "  批次 40/118: Loss=0.3159, Acc=88.34%\n",
      "  批次 50/118: Loss=0.1169, Acc=89.09%\n",
      "  批次 60/118: Loss=0.2777, Acc=89.40%\n",
      "  批次 70/118: Loss=0.2766, Acc=89.39%\n",
      "  批次 80/118: Loss=0.2638, Acc=89.31%\n",
      "  批次 90/118: Loss=0.4976, Acc=89.32%\n",
      "  批次 100/118: Loss=0.3258, Acc=89.51%\n",
      "  批次 110/118: Loss=0.3570, Acc=89.58%\n",
      "✅ Epoch 2 驗證中...\n",
      "\n",
      "📊 Epoch 2 結果:\n",
      "  🚂 訓練 - Loss: 0.2994, Acc: 89.67%\n",
      "  ✅ 驗證 - Loss: 0.3062, Acc: 89.89%\n",
      "  📅 學習率: 0.001000\n",
      "  🎯 新的最佳模型！驗證準確率: 89.89%\n",
      "\n",
      "🔄 Epoch 3/20\n",
      "------------------------------\n",
      "🚂 Epoch 3 訓練中...\n",
      "  批次 0/118: Loss=0.0807, Acc=96.88%\n",
      "  批次 10/118: Loss=0.1068, Acc=93.18%\n",
      "  批次 20/118: Loss=0.2319, Acc=92.71%\n",
      "  批次 30/118: Loss=0.1649, Acc=93.75%\n",
      "  批次 40/118: Loss=0.2197, Acc=94.51%\n",
      "  批次 50/118: Loss=0.3854, Acc=94.49%\n",
      "  批次 60/118: Loss=0.2218, Acc=94.36%\n",
      "  批次 70/118: Loss=0.1461, Acc=93.88%\n",
      "  批次 80/118: Loss=0.2159, Acc=93.98%\n",
      "  批次 90/118: Loss=0.4038, Acc=93.51%\n",
      "  批次 100/118: Loss=0.2200, Acc=93.41%\n",
      "  批次 110/118: Loss=0.1577, Acc=93.47%\n",
      "✅ Epoch 3 驗證中...\n",
      "\n",
      "📊 Epoch 3 結果:\n",
      "  🚂 訓練 - Loss: 0.2067, Acc: 93.41%\n",
      "  ✅ 驗證 - Loss: 0.3178, Acc: 88.84%\n",
      "  📅 學習率: 0.001000\n",
      "\n",
      "🔄 Epoch 4/20\n",
      "------------------------------\n",
      "🚂 Epoch 4 訓練中...\n",
      "  批次 0/118: Loss=0.2201, Acc=87.50%\n",
      "  批次 10/118: Loss=0.0455, Acc=95.74%\n",
      "  批次 20/118: Loss=0.0757, Acc=96.58%\n",
      "  批次 30/118: Loss=0.0931, Acc=96.07%\n",
      "  批次 40/118: Loss=0.0823, Acc=95.81%\n",
      "  批次 50/118: Loss=0.3279, Acc=95.47%\n",
      "  批次 60/118: Loss=0.1571, Acc=94.93%\n",
      "  批次 70/118: Loss=0.1311, Acc=95.11%\n",
      "  批次 80/118: Loss=0.1267, Acc=95.18%\n",
      "  批次 90/118: Loss=0.1562, Acc=95.30%\n",
      "  批次 100/118: Loss=0.2629, Acc=95.30%\n",
      "  批次 110/118: Loss=0.0615, Acc=95.52%\n",
      "✅ Epoch 4 驗證中...\n",
      "\n",
      "📊 Epoch 4 結果:\n",
      "  🚂 訓練 - Loss: 0.1446, Acc: 95.50%\n",
      "  ✅ 驗證 - Loss: 1.3897, Acc: 76.11%\n",
      "  📅 學習率: 0.001000\n",
      "\n",
      "🔄 Epoch 5/20\n",
      "------------------------------\n",
      "🚂 Epoch 5 訓練中...\n",
      "  批次 0/118: Loss=0.1061, Acc=93.75%\n",
      "  批次 10/118: Loss=0.2153, Acc=93.75%\n",
      "  批次 20/118: Loss=0.2976, Acc=93.75%\n",
      "  批次 30/118: Loss=0.1673, Acc=93.75%\n",
      "  批次 40/118: Loss=0.0847, Acc=93.29%\n",
      "  批次 50/118: Loss=0.1466, Acc=93.20%\n",
      "  批次 60/118: Loss=0.0301, Acc=93.49%\n",
      "  批次 70/118: Loss=0.1947, Acc=93.27%\n",
      "  批次 80/118: Loss=0.4251, Acc=93.40%\n",
      "  批次 90/118: Loss=0.0696, Acc=93.51%\n",
      "  批次 100/118: Loss=0.2916, Acc=93.90%\n",
      "  批次 110/118: Loss=0.1182, Acc=93.98%\n",
      "✅ Epoch 5 驗證中...\n",
      "\n",
      "📊 Epoch 5 結果:\n",
      "  🚂 訓練 - Loss: 0.1760, Acc: 94.12%\n",
      "  ✅ 驗證 - Loss: 0.4827, Acc: 85.26%\n",
      "  📅 學習率: 0.001000\n",
      "\n",
      "🔄 Epoch 6/20\n",
      "------------------------------\n",
      "🚂 Epoch 6 訓練中...\n",
      "  批次 0/118: Loss=0.0902, Acc=96.88%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# 🚀 開始訓練！\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m history = train_model(\n\u001b[32m     72\u001b[39m     model=model,\n\u001b[32m     73\u001b[39m     train_loader=train_loader,\n\u001b[32m     74\u001b[39m     val_loader=val_loader,\n\u001b[32m     75\u001b[39m     criterion=criterion,\n\u001b[32m     76\u001b[39m     optimizer=optimizer,\n\u001b[32m     77\u001b[39m     scheduler=scheduler,\n\u001b[32m     78\u001b[39m     device=device,\n\u001b[32m     79\u001b[39m     num_epochs=\u001b[32m20\u001b[39m,\n\u001b[32m     80\u001b[39m     save_path=\u001b[33m'\u001b[39m\u001b[33mresnet50_plant_classifier.pth\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, save_path)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 🚂 訓練階段\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m train_loss, train_acc = train_one_epoch(\n\u001b[32m     28\u001b[39m     model, train_loader, criterion, optimizer, device, epoch\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# ✅ 驗證階段\u001b[39;00m\n\u001b[32m     32\u001b[39m val_loss, val_acc = validate_one_epoch(\n\u001b[32m     33\u001b[39m     model, val_loader, criterion, device, epoch\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device, epoch)\u001b[39m\n\u001b[32m     22\u001b[39m optimizer.step()\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 📊 統計\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m running_loss += loss.item()\n\u001b[32m     26\u001b[39m _, predicted = outputs.max(\u001b[32m1\u001b[39m)\n\u001b[32m     27\u001b[39m total += labels.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                device, num_epochs=20, save_path='best_model.pth'):\n",
    "    \"\"\"完整訓練流程\"\"\"\n",
    "    \n",
    "    print(\"🚀 開始訓練 ResNet-50\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"📊 訓練集批次數: {len(train_loader)}\")\n",
    "    print(f\"📊 驗證集批次數: {len(val_loader)}\")\n",
    "    print(f\"⏰ 總訓練輪數: {num_epochs}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 📈 記錄訓練歷史\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"\\n🔄 Epoch {epoch}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # 🚂 訓練階段\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch\n",
    "        )\n",
    "        \n",
    "        # ✅ 驗證階段\n",
    "        val_loss, val_acc = validate_one_epoch(\n",
    "            model, val_loader, criterion, device, epoch\n",
    "        )\n",
    "        \n",
    "        # 📅 更新學習率\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # 📊 記錄結果\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # 📈 顯示結果\n",
    "        print(f\"\\n📊 Epoch {epoch} 結果:\")\n",
    "        print(f\"  🚂 訓練 - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  ✅ 驗證 - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%\")\n",
    "        print(f\"  📅 學習率: {current_lr:.6f}\")\n",
    "        \n",
    "        # 💾 儲存最佳模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'history': history\n",
    "            }, save_path)\n",
    "            print(f\"  🎯 新的最佳模型！驗證準確率: {val_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n🎉 訓練完成！\")\n",
    "    print(f\"🏆 最佳驗證準確率: {best_val_acc:.2f}%\")\n",
    "    print(f\"💾 模型已儲存至: {save_path}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 🚀 開始訓練！\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    num_epochs=20,\n",
    "    save_path='resnet50_plant_classifier.pth'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b57ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def plot_training_history(history, save_path='training_history.png'):\n",
    "    \"\"\"繪製訓練歷史圖表\"\"\"\n",
    "    \n",
    "    print(\"📊 繪製訓練歷史:\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # 設置中文字體和風格\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS']\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    # 創建 2x2 子圖\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('🌱 植物分類模型訓練結果', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # 📉 Loss 曲線\n",
    "    axes[0, 0].plot(epochs, history['train_loss'], 'b-o', label='訓練 Loss', linewidth=2, markersize=4)\n",
    "    axes[0, 0].plot(epochs, history['val_loss'], 'r-s', label='驗證 Loss', linewidth=2, markersize=4)\n",
    "    axes[0, 0].set_title('📉 Loss 變化曲線', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 📈 準確率曲線\n",
    "    axes[0, 1].plot(epochs, history['train_acc'], 'b-o', label='訓練準確率', linewidth=2, markersize=4)\n",
    "    axes[0, 1].plot(epochs, history['val_acc'], 'r-s', label='驗證準確率', linewidth=2, markersize=4)\n",
    "    axes[0, 1].set_title('📈 準確率變化曲線', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('準確率 (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 📊 最終幾個 epoch 的詳細比較\n",
    "    last_n = min(5, len(epochs))\n",
    "    last_epochs = epochs[-last_n:]\n",
    "    \n",
    "    axes[1, 0].bar([f'E{e}' for e in last_epochs], \n",
    "                   [history['train_acc'][e-1] for e in last_epochs], \n",
    "                   alpha=0.7, color='skyblue', label='訓練')\n",
    "    axes[1, 0].bar([f'E{e}' for e in last_epochs], \n",
    "                   [history['val_acc'][e-1] for e in last_epochs], \n",
    "                   alpha=0.7, color='lightcoral', label='驗證')\n",
    "    axes[1, 0].set_title(f'📊 最後 {last_n} 個 Epoch 準確率比較', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('準確率 (%)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 📈 學習曲線分析\n",
    "    train_val_gap = [abs(t - v) for t, v in zip(history['train_acc'], history['val_acc'])]\n",
    "    axes[1, 1].plot(epochs, train_val_gap, 'g-^', label='訓練-驗證差距', linewidth=2, markersize=4)\n",
    "    axes[1, 1].axhline(y=5, color='orange', linestyle='--', alpha=0.7, label='理想差距 (5%)')\n",
    "    axes[1, 1].set_title('📈 過擬合分析', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('準確率差距 (%)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 📊 打印統計信息\n",
    "    print(f\"📊 訓練統計:\")\n",
    "    print(f\"   最佳訓練準確率: {max(history['train_acc']):.2f}%\")\n",
    "    print(f\"   最佳驗證準確率: {max(history['val_acc']):.2f}%\")\n",
    "    print(f\"   最終訓練準確率: {history['train_acc'][-1]:.2f}%\")\n",
    "    print(f\"   最終驗證準確率: {history['val_acc'][-1]:.2f}%\")\n",
    "    print(f\"   最終過擬合程度: {abs(history['train_acc'][-1] - history['val_acc'][-1]):.2f}%\")\n",
    "\n",
    "# 🎨 繪製訓練歷史\n",
    "plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6705b2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 開始測試預測流程:\n",
      "==================================================\n",
      "📥 載入模型: resnet50_plant_classifier.pth\n",
      "✅ 模型載入成功! (最佳驗證準確率: 89.89%)\n",
      "📊 測試資料載入完成: 794 張圖片\n",
      "🔍 開始預測測試資料集:\n",
      "========================================\n",
      "📊 測試批次數: 25\n",
      "📁 預測結果將保存至: test_predictions.csv\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀 預測中: 100%|██████████| 25/25 [00:06<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 預測完成！\n",
      "📊 總預測樣本數: 794\n",
      "📁 結果已保存至: test_predictions.csv\n",
      "\n",
      "📊 預測統計:\n",
      "   Loose Silky-bent: 145 張 (18.3%)\n",
      "   Common Chickweed: 99 張 (12.5%)\n",
      "   Small-flowered Cranesbill: 85 張 (10.7%)\n",
      "   Scentless Mayweed: 82 張 (10.3%)\n",
      "   Sugar beet: 72 張 (9.1%)\n",
      "   Fat Hen: 66 張 (8.3%)\n",
      "   Charlock: 64 張 (8.1%)\n",
      "   Cleavers: 48 張 (6.0%)\n",
      "   Shepherds Purse: 45 張 (5.7%)\n",
      "   Common wheat: 38 張 (4.8%)\n",
      "   Maize: 36 張 (4.5%)\n",
      "   Black-grass: 14 張 (1.8%)\n",
      "\n",
      "🎯 預測信心度統計:\n",
      "   平均信心度: 0.910\n",
      "   最高信心度: 1.000\n",
      "   最低信心度: 0.310\n",
      "   高信心度 (>0.9): 588 張\n",
      "   低信心度 (<0.5): 17 張\n",
      "\n",
      "📋 前 10 個預測結果:\n",
      "         file                   species\n",
      "0021e90e4.png Small-flowered Cranesbill\n",
      "003d61042.png                   Fat Hen\n",
      "007b3da8b.png                Sugar beet\n",
      "0086a6340.png          Common Chickweed\n",
      "00c47e980.png                Sugar beet\n",
      "00d090cde.png          Loose Silky-bent\n",
      "00ef713a8.png          Common Chickweed\n",
      "01291174f.png                   Fat Hen\n",
      "026716f9b.png          Loose Silky-bent\n",
      "02cfeb38d.png          Loose Silky-bent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def predict_test_dataset(model, test_loader, device, class_names, save_path='predictions.csv'):\n",
    "    \"\"\"對測試資料集進行預測並輸出 CSV\"\"\"\n",
    "    \n",
    "    print(\"🔍 開始預測測試資料集:\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"📊 測試批次數: {len(test_loader)}\")\n",
    "    print(f\"📁 預測結果將保存至: {save_path}\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # 儲存預測結果\n",
    "    predictions_list = []\n",
    "    filenames_list = []\n",
    "    confidences_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 使用 tqdm 顯示進度條\n",
    "        for batch_idx, (images, filenames) in enumerate(tqdm(test_loader, desc=\"🚀 預測中\")):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # 前向傳播\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidences, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            # 轉換為 CPU 並收集結果\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            confidences = confidences.cpu().numpy()\n",
    "            \n",
    "            # 將預測類別索引轉換為類別名稱\n",
    "            for i, (pred_idx, conf, filename) in enumerate(zip(predicted, confidences, filenames)):\n",
    "                species_name = class_names[pred_idx]\n",
    "                \n",
    "                predictions_list.append(species_name)\n",
    "                filenames_list.append(filename)\n",
    "                confidences_list.append(conf)\n",
    "    \n",
    "    # 建立 DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'file': filenames_list,\n",
    "        'species': predictions_list,\n",
    "        'confidence': confidences_list\n",
    "    })\n",
    "    \n",
    "    # 按檔名排序\n",
    "    results_df = results_df.sort_values('file').reset_index(drop=True)\n",
    "    \n",
    "    # 保存 CSV（只包含 file 和 species 欄位，符合你的格式要求）\n",
    "    final_df = results_df[['file', 'species']]\n",
    "    final_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ 預測完成！\")\n",
    "    print(f\"📊 總預測樣本數: {len(results_df)}\")\n",
    "    print(f\"📁 結果已保存至: {save_path}\")\n",
    "    \n",
    "    # 顯示預測統計\n",
    "    print(f\"\\n📊 預測統計:\")\n",
    "    species_counts = results_df['species'].value_counts()\n",
    "    for species, count in species_counts.items():\n",
    "        percentage = (count / len(results_df)) * 100\n",
    "        print(f\"   {species}: {count} 張 ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 顯示信心度統計\n",
    "    print(f\"\\n🎯 預測信心度統計:\")\n",
    "    print(f\"   平均信心度: {results_df['confidence'].mean():.3f}\")\n",
    "    print(f\"   最高信心度: {results_df['confidence'].max():.3f}\")\n",
    "    print(f\"   最低信心度: {results_df['confidence'].min():.3f}\")\n",
    "    print(f\"   高信心度 (>0.9): {(results_df['confidence'] > 0.9).sum()} 張\")\n",
    "    print(f\"   低信心度 (<0.5): {(results_df['confidence'] < 0.5).sum()} 張\")\n",
    "    \n",
    "    # 顯示前幾個預測結果作為範例\n",
    "    print(f\"\\n📋 前 10 個預測結果:\")\n",
    "    print(final_df.head(10).to_string(index=False))\n",
    "    \n",
    "    return results_df, final_df\n",
    "\n",
    "# 🚀 執行測試預測\n",
    "def run_test_prediction():\n",
    "    \"\"\"執行完整的測試預測流程\"\"\"\n",
    "    \n",
    "    print(\"🚀 開始測試預測流程:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. 載入最佳模型\n",
    "    model_path = 'resnet50_plant_classifier.pth'\n",
    "    print(f\"📥 載入模型: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"✅ 模型載入成功! (最佳驗證準確率: {checkpoint['best_val_acc']:.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 模型載入失敗: {e}\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    if len(test_loader) == 0:\n",
    "        print(\"❌ 測試資料夾為空或無法讀取\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📊 測試資料載入完成: {len(test_loader.dataset)} 張圖片\")\n",
    "    \n",
    "    # 3. 進行預測\n",
    "    results_df, final_df = predict_test_dataset(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        class_names=PLANT_CLASSES,\n",
    "        save_path='test_predictions.csv'\n",
    "    )\n",
    "    \n",
    "    return results_df, final_df\n",
    "\n",
    "# 🎯 執行預測\n",
    "prediction_results = run_test_prediction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
